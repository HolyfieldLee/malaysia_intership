{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde8227-7ed3-4b95-8d40-9e01e8d1f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px  # if needed for further plotting\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "def process_resource_room(filepath):\n",
    "    \"\"\"\n",
    "    Processes the resource room Excel file and returns a cleaned and categorized DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): The path to the Excel file (e.g., '/content/CSD - Resource Room.xlsx').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed DataFrame with an added 'Type' column.\n",
    "    \"\"\"\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(filepath)\n",
    "    Resource_Room = pd.DataFrame(df)\n",
    "    \n",
    "    # Remove unwanted columns\n",
    "    Resource_Room = Resource_Room.drop(labels='Campus', axis=1)\n",
    "    Resource_Room = Resource_Room.drop(labels='Workshop', axis=1)\n",
    "    \n",
    "    # Exclude rows containing 'IMus'\n",
    "    Resource_Room = Resource_Room[\n",
    "        ~Resource_Room.apply(lambda row: row.astype(str).str.contains('IMus', case=False, na=False).any(), axis=1)\n",
    "    ]\n",
    "    \n",
    "    # Exclude rows where Lecture, Tutorial, Lab are all 'N'\n",
    "    Resource_Room = Resource_Room[~(Resource_Room[['Lecture', 'Tutorial', 'Lab']].eq('N').all(axis=1))]\n",
    "    \n",
    "    # Fill NA values with 'N' and replace 'N' in Capacity with '20'\n",
    "    Resource_Room = Resource_Room.fillna('N')\n",
    "    Resource_Room['Capacity'] = Resource_Room['Capacity'].replace('N', '20')\n",
    "    \n",
    "    # Drop rows with Capacity equal to 0\n",
    "    Resource_Room = Resource_Room.drop(Resource_Room[Resource_Room['Capacity'] == 0].index)\n",
    "    \n",
    "    # Categorize as General where Lecture, Tutorial, Lab are all 'Y'\n",
    "    conditions = [['Y', 'Y', 'Y']]\n",
    "    columns_to_check = ['Lecture', 'Tutorial', 'Lab']\n",
    "    General = Resource_Room[\n",
    "        Resource_Room[columns_to_check].apply(tuple, axis=1).isin(map(tuple, conditions))\n",
    "    ]\n",
    "    \n",
    "    # Exclude specific conditions to form etc_Room (not strictly needed for exclusion logic in this snippet)\n",
    "    conditions_to_exclude = [['Y', 'Y', 'N'], ['N', 'Y', 'Y']]\n",
    "    etc_Room = Resource_Room[\n",
    "        ~Resource_Room[columns_to_check].apply(tuple, axis=1).isin(map(tuple, conditions))\n",
    "    ]\n",
    "    \n",
    "    # Identify Kitchen and Design related rooms\n",
    "    Kitchen = etc_Room[\n",
    "        etc_Room.apply(lambda row: row.astype(str).str.contains('Kitchen', regex=False).any(), axis=1)\n",
    "    ]\n",
    "    Design = etc_Room[\n",
    "        etc_Room['Description'].str.contains('DESIGN', case=False, na=False)\n",
    "    ]\n",
    "    df_combined = pd.concat([Kitchen, Design])\n",
    "    \n",
    "    # Get remaining rows excluding those in df_combined\n",
    "    LL = etc_Room[\n",
    "        ~etc_Room.apply(tuple, axis=1).isin(df_combined.apply(tuple, axis=1))\n",
    "    ]\n",
    "    \n",
    "    # Categorize Lab rooms: where [Lecture, Tutorial, Lab] == ['N', 'N', 'Y']\n",
    "    lab_condition = [['N', 'N', 'Y']]\n",
    "    Lab = LL[\n",
    "        LL[columns_to_check].apply(tuple, axis=1).isin(map(tuple, lab_condition)) &\n",
    "        ~LL.apply(tuple, axis=1).isin(df_combined.apply(tuple, axis=1))\n",
    "    ]\n",
    "    \n",
    "    # Categorize Lecture rooms: where [Lecture, Tutorial, Lab] == ['Y', 'N', 'N']\n",
    "    lecture_condition = [['Y', 'N', 'N']]\n",
    "    Lecture = LL[\n",
    "        LL[columns_to_check].apply(tuple, axis=1).isin(map(tuple, lecture_condition)) &\n",
    "        ~LL.apply(tuple, axis=1).isin(df_combined.apply(tuple, axis=1))\n",
    "    ]\n",
    "    \n",
    "    # Update df_combined with Lab and Lecture, then get ETC as remaining rows\n",
    "    df_combined = pd.concat([Lab, Lecture])\n",
    "    ETC = LL[~LL.apply(tuple, axis=1).isin(df_combined.apply(tuple, axis=1))]\n",
    "    \n",
    "    # Assign types\n",
    "    General['Type'] = 'General'\n",
    "    Lab['Type'] = 'Lab'\n",
    "    Kitchen['Type'] = 'Kitchen'\n",
    "    Design['Type'] = 'Art'\n",
    "    Lecture['Type'] = 'Lecture'\n",
    "    ETC['Type'] = 'Etc'\n",
    "    \n",
    "    # Combine all categorized DataFrames\n",
    "    df_final = pd.concat([General, ETC, Kitchen, Design, Lab, Lecture], ignore_index=True)\n",
    "    df_final = df_final.drop_duplicates(keep='first')\n",
    "    \n",
    "    # Override type to 'PBL' if any row contains 'PBL'\n",
    "    df_final.loc[\n",
    "        df_final.astype(str).apply(lambda row: row.str.contains('PBL', case=False, na=False).any(), axis=1),\n",
    "        'Type'\n",
    "    ] = 'PBL'\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "def preprocess_offer(file_path):\n",
    "    # 엑셀 파일을 DataFrame으로 불러옵니다.\n",
    "    offer = pd.read_excel(file_path)\n",
    "\n",
    "    offer.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    offer.drop(offer.index[1157], axis=0, inplace=True)\n",
    "    offer['Capacity'] = offer['Capacity'].astype(int)\n",
    "    offer['Min Per Session'] = offer['Min Per Session'].astype(int)\n",
    "\n",
    "    offer['Session'] = offer['Session'].str.upper()\n",
    "    offer['Lecturer'] = offer['Lecturer'].str.upper()\n",
    "    offer['CourseCode'] = offer['CourseCode'].str.upper()\n",
    "    offer['FacultyCode'] = offer['FacultyCode'].str.upper()\n",
    "\n",
    "    offer['Session'] = offer['Session'].str.replace(r'\\(S\\)', '', regex=True)\n",
    "\n",
    "    # \"COMBINED TO /\"를 복사하여 error 테이블에 저장. 이후 원본 데이터에서 삭제.\n",
    "    mask = offer['Session'].str.contains(\"COMBINED TO /\", na=False)\n",
    "\n",
    "    # error 데이터프레임에 해당 행들을 복사하여 저장합니다.\n",
    "    error = offer[mask].copy()\n",
    "\n",
    "    # 원본 offer 데이터프레임에서 해당 행들을 삭제합니다.\n",
    "    offer.drop(offer[mask].index, inplace=True)\n",
    "\n",
    "    #\"GROUP A\", \"GROUP B\", \"GROUP C\" 등 해당하는 행을 찾고, Session 값을 \"LECTURE\"로 변경\n",
    "    offer.loc[offer['Session'].str.contains(r'^GROUP\\s+[A-Z]$', na=False), 'Session'] = 'LECTURE'\n",
    "\n",
    "    group_cols = ['CourseCode', 'FacultyCode', 'Session', 'Capacity', 'Min Per Session', 'Lecturer']\n",
    "\n",
    "    # 그룹별로 중복된 행을 처리합니다.\n",
    "    for _, group in offer.groupby(group_cols):\n",
    "        if len(group) > 1:  # 중복 그룹인 경우\n",
    "            # 원래 Session 값을 앞뒤 공백 제거 후 사용합니다.\n",
    "            orig_session = group.iloc[0]['Session'].strip()\n",
    "            # Session 값이 숫자로 끝나는지 검사 (예: \"TUTORIAL 1\")\n",
    "            m = re.search(r'^(.*?)(\\d+)$', orig_session)\n",
    "            if m:\n",
    "                base = m.group(1).strip()  # 문자 부분 (예: \"TUTORIAL\")\n",
    "                start_num = int(m.group(2))  # 기존에 붙은 숫자 (예: 1)\n",
    "            else:\n",
    "                base = orig_session\n",
    "                start_num = 1\n",
    "\n",
    "            # 그룹 내 각 행에 대해 순차적으로 번호를 붙여 Session 값을 변경합니다.\n",
    "            for offset, idx in enumerate(group.index):\n",
    "                new_session = f\"{base} {start_num + offset}\"\n",
    "                offer.at[idx, 'Session'] = new_session\n",
    "\n",
    "    # (초기 전제: offer DataFrame과 error DataFrame이 존재함; error가 없으면 빈 DataFrame 생성)\n",
    "    if 'error' not in globals():\n",
    "        error = pd.DataFrame()\n",
    "\n",
    "    ### Step 1. offer에서 \"COMBINED TO\" 행 추출 → child_class로 저장, offer에서는 제거\n",
    "    child_class = offer[offer['Session'].str.contains('COMBINED TO', na=False)].copy()\n",
    "    offer.drop(child_class.index, inplace=True)\n",
    "\n",
    "    ### Step 2. child_class의 Session 열에서 과목코드 추출\n",
    "    child_class['extracted_code'] = child_class['Session'].str.extract(r'COMBINED TO\\s+([A-Z0-9]+)', expand=False)\n",
    "\n",
    "    ### Step 3. child_class 내에서 오류 및 정상/후손 분리\n",
    "\n",
    "    # (A) \"자기 자신 참조\" 조건: 추출한 코드가 해당 행의 CourseCode와 같으면 → 오류\n",
    "    self_ref = child_class['extracted_code'] == child_class['CourseCode']\n",
    "\n",
    "    # (B) 정상(child) 조건: 자기 자신 참조가 아니고, 추출한 코드가 offer의 CourseCode에 존재하는 경우\n",
    "    valid_child_mask = (~self_ref) & (child_class['extracted_code'].isin(offer['CourseCode']))\n",
    "\n",
    "    # (C) 후손(grandchild) 후보: 자기 자신 참조가 아니고, 추출한 코드가 offer에는 없지만, child_class의 CourseCode에는 존재하는 경우  \n",
    "    #     (즉, 부모(대상 CourseCode)가 offer에 없으므로 자식끼리 연결되어 있음을 의미)\n",
    "    valid_grand_mask = (~self_ref) & (~child_class['extracted_code'].isin(offer['CourseCode'])) & \\\n",
    "                        (child_class['extracted_code'].isin(child_class['CourseCode']))\n",
    "\n",
    "    # (D) 오류 조건:  \n",
    "    #     - 자기 자신 참조인 경우  \n",
    "    #     - 또는 추출한 코드가 offer에도 child_class에도 존재하지 않는 경우\n",
    "    error_mask = self_ref | ((~child_class['extracted_code'].isin(offer['CourseCode'])) & \n",
    "                               (~child_class['extracted_code'].isin(child_class['CourseCode'])))\n",
    "\n",
    "    # child_class 오류 처리: 추출\n",
    "    child_error = child_class[error_mask].copy()\n",
    "\n",
    "    # 정상 child_class (valid_child) 추출\n",
    "    valid_child = child_class[valid_child_mask].copy()\n",
    "\n",
    "    # 후보 후손(grandchild) 추출\n",
    "    candidate_grand = child_class[valid_grand_mask].copy()\n",
    "\n",
    "    ### Step 4. grand_child_class 내에서 추가 오류 처리\n",
    "    # 오류 조건 (grandchild): 자기 자신 참조 → 오류\n",
    "    grand_self_ref = candidate_grand['extracted_code'] == candidate_grand['CourseCode']\n",
    "    error_grand = candidate_grand[grand_self_ref].copy()\n",
    "\n",
    "    # 최종 grand_child_class: 후보에서 자기 자신 참조 오류 제거\n",
    "    grand_child_class = candidate_grand[~grand_self_ref].copy()\n",
    "\n",
    "    # 최종 error: 기존 child 오류와 후손에서 발생한 오류를 모두 누적\n",
    "    error_df = pd.concat([child_error, error_grand], ignore_index=True)\n",
    "    error = pd.concat([error, error_df], ignore_index=True)\n",
    "\n",
    "    ### 최종 정상 데이터\n",
    "    # child_class는 valid_child로 업데이트 (offer의 부모가 존재하는 경우)\n",
    "    child_class = valid_child.copy()\n",
    "    # grand_child_class는 위에서 구한 대로\n",
    "\n",
    "    # error DataFrame이 없으면 빈 DataFrame 생성\n",
    "    if 'error' not in globals():\n",
    "        error = pd.DataFrame()\n",
    "\n",
    "    ##############################################\n",
    "    # 교차검증 1: child_class에서 자기 자신 참조하는 행 처리\n",
    "    ##############################################\n",
    "    child_self_ref_mask = (child_class['extracted_code'] == child_class['CourseCode'])\n",
    "    child_self_ref_errors = child_class[child_self_ref_mask].copy()\n",
    "    error = pd.concat([error, child_self_ref_errors], ignore_index=True)\n",
    "    child_class = child_class[~child_self_ref_mask].copy()\n",
    "\n",
    "    ##############################################\n",
    "    # 교차검증 2: child_class에서 추출한 과목코드가 offer의 CourseCode에 없음(부모 없음)\n",
    "    ##############################################\n",
    "    child_missing_parent_mask = ~child_class['extracted_code'].isin(offer['CourseCode'])\n",
    "    child_missing_parent_errors = child_class[child_missing_parent_mask].copy()\n",
    "    error = pd.concat([error, child_missing_parent_errors], ignore_index=True)\n",
    "    child_class = child_class[~child_missing_parent_mask].copy()\n",
    "\n",
    "    ##############################################\n",
    "    # 교차검증 3: offer에서 자기 자신 참조하는 행 처리\n",
    "    # (offer에 COMBINED TO가 남아있다면 해당 행에 대해 extracted_code를 추출)\n",
    "    ##############################################\n",
    "    offer_combined_mask = offer['Session'].str.contains('COMBINED TO', na=False)\n",
    "    if offer_combined_mask.any():\n",
    "        offer.loc[offer_combined_mask, 'extracted_code'] = offer.loc[offer_combined_mask, 'Session'].str.extract(r'COMBINED TO\\s+([A-Z0-9]+)', expand=False)\n",
    "        offer_self_ref_mask = (offer['extracted_code'] == offer['CourseCode'])\n",
    "        offer_self_ref_errors = offer[offer_self_ref_mask].copy()\n",
    "        error = pd.concat([error, offer_self_ref_errors], ignore_index=True)\n",
    "        offer.drop(offer[offer_self_ref_mask].index, inplace=True)\n",
    "\n",
    "    ##############################################\n",
    "    # 교차검증 4: grand_child_class에서 자기 자신 참조하는 행 처리\n",
    "    ##############################################\n",
    "    grand_self_ref_mask = (grand_child_class['extracted_code'] == grand_child_class['CourseCode'])\n",
    "    grand_self_ref_errors = grand_child_class[grand_self_ref_mask].copy()\n",
    "    error = pd.concat([error, grand_self_ref_errors], ignore_index=True)\n",
    "    grand_child_class = grand_child_class[~grand_self_ref_mask].copy()\n",
    "\n",
    "    ##############################################\n",
    "    # 교차검증 5: grand_child_class에서 추출한 과목코드가 offer의 CourseCode에 없음(부모 없음)\n",
    "    ##############################################\n",
    "    grand_missing_parent_mask = ~grand_child_class['extracted_code'].isin(offer['CourseCode'])\n",
    "    grand_missing_parent_errors = grand_child_class[grand_missing_parent_mask].copy()\n",
    "    error = pd.concat([error, grand_missing_parent_errors], ignore_index=True)\n",
    "    grand_child_class = grand_child_class[~grand_missing_parent_mask].copy()\n",
    "\n",
    "    ##############################################\n",
    "    # 교차검증 6: 부모(offer 또는 child_class)에서 드랍된 행과 연결된 자식(또는 손자) 행 처리\n",
    "    # 드랍된 행들의 CourseCode를 모아서, 이 코드를 extracted_code로 사용하는 행이 있다면 error로 처리\n",
    "    ##############################################\n",
    "    # 지금까지 error에 추가된 행들의 CourseCode를 모읍니다.\n",
    "    dropped_codes = set(error['CourseCode'].unique())\n",
    "\n",
    "    # child_class에서 연결된 자식 행 검사\n",
    "    child_linked_mask = child_class['extracted_code'].isin(dropped_codes)\n",
    "    child_linked_errors = child_class[child_linked_mask].copy()\n",
    "    error = pd.concat([error, child_linked_errors], ignore_index=True)\n",
    "    child_class = child_class[~child_linked_mask].copy()\n",
    "\n",
    "    # grand_child_class에서 연결된 손자 행 검사\n",
    "    grand_linked_mask = grand_child_class['extracted_code'].isin(dropped_codes)\n",
    "    grand_linked_errors = grand_child_class[grand_linked_mask].copy()\n",
    "    error = pd.concat([error, grand_linked_errors], ignore_index=True)\n",
    "    grand_child_class = grand_child_class[~grand_linked_mask].copy()\n",
    "\n",
    "    # child_class의 각 행을 순회하며 조건에 맞는 offer 행의 Capacity에 child_class의 Capacity를 합산합니다.\n",
    "    for idx, child_row in child_class.iterrows():\n",
    "        # 조건: offer의 CourseCode, Min Per Session, Lecturer가 child_row의 extracted_code, Min Per Session, Lecturer와 일치\n",
    "        mask = (\n",
    "            (offer['CourseCode'] == child_row['extracted_code']) &\n",
    "            (offer['Min Per Session'] == child_row['Min Per Session']) &\n",
    "            (offer['Lecturer'] == child_row['Lecturer'])\n",
    "        )\n",
    "        # 일치하는 행이 있다면, offer의 Capacity에 child_row의 Capacity를 더함\n",
    "        if mask.any():\n",
    "            offer.loc[mask, 'Capacity'] += child_row['Capacity']\n",
    "\n",
    "    # 기존 조건\n",
    "    conditions = [\n",
    "        offer['Session'].str.contains('LECTURE & TUTORIAL', na=False, case=False),\n",
    "        offer['Session'].str.contains('TUTORIAL', na=False, case=False),\n",
    "        offer['Session'].str.contains('LECTURE', na=False, case=False),\n",
    "        offer['Session'].str.contains('LAB', na=False, case=False),\n",
    "        offer['Session'].str.contains('PBL 1', na=False, case=False),\n",
    "        offer['Session'].str.contains('HAND DRAWING|CAD DRAWING 2|CAD DRAWING 1', na=False, case=False),\n",
    "        offer['Session'].str.contains('KITCHEN', na=False, case=False),\n",
    "        offer['Session'].str.contains('OPTOM CLINIC|SOO - EXAM CLINIC', na=False, case=False)\n",
    "    ]\n",
    "\n",
    "    # 기존 선택지 + 새 선택지\n",
    "    choices = [\n",
    "        'GENERAL',\n",
    "        'TUTORIAL',\n",
    "        'LECTURE',\n",
    "        'LAB',\n",
    "        'PBL',\n",
    "        'ART',\n",
    "        'KITCHEN',\n",
    "        'LECTURE'\n",
    "    ]\n",
    "\n",
    "    # 조건을 적용하여 'Category' 열 생성\n",
    "    offer['Category'] = np.select(conditions, choices, default=np.nan)\n",
    "    \n",
    "    return offer\n",
    "\n",
    "\n",
    "def expand_room_slots(df_final):\n",
    "    time_slots = ['8-11', '13-16', '18-21']\n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri']\n",
    "\n",
    "    expanded_rooms = []\n",
    "    for _, row in df_final.iterrows():\n",
    "        for day in days:\n",
    "            for time in time_slots:\n",
    "                expanded_rooms.append({\n",
    "                    'Resource Code': row['Resource Code'],\n",
    "                    'Type': row['Type'],\n",
    "                    'Capacity': row['Capacity'],\n",
    "                    'Assigned Day': day,\n",
    "                    'Assigned Time Slot': time,\n",
    "                    'Lecture': row.get('Lecture', 'N'),\n",
    "                    'Tutorial': row.get('Tutorial', 'N'),\n",
    "                    'Lab': row.get('Lab', 'N')\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(expanded_rooms)\n",
    "\n",
    "def preprocess_offers(offer, max_room_capacity):\n",
    "    expanded_offers = []\n",
    "    for _, row in offer.iterrows():\n",
    "        remaining_students = row['Capacity']\n",
    "        total_duration = row['Min Per Session']\n",
    "        session_count = 1\n",
    "\n",
    "        while remaining_students > 0:\n",
    "            assigned_capacity = min(max_room_capacity, remaining_students)\n",
    "            remaining_students -= assigned_capacity\n",
    "\n",
    "            remaining_duration = total_duration\n",
    "            sub_session = 1\n",
    "\n",
    "            while remaining_duration > 0:\n",
    "                session_duration = min(180, remaining_duration)\n",
    "                remaining_duration -= session_duration\n",
    "\n",
    "                expanded_offers.append({\n",
    "                    'Course Code': f\"{row['CourseCode']}_S{session_count}_D{sub_session}\",\n",
    "                    'Capacity': assigned_capacity,\n",
    "                    'Min Per Session': session_duration,\n",
    "                    'Category': row['Category'],\n",
    "                    'Lecturer': row['Lecturer']\n",
    "                })\n",
    "                sub_session += 1\n",
    "\n",
    "            session_count += 1\n",
    "\n",
    "    return pd.DataFrame(expanded_offers)\n",
    "\n",
    "def match_classroom_type(df_final, offer):\n",
    "    offer['Category'] = offer['Category'].str.lower()\n",
    "    df_final['Type'] = df_final['Type'].str.lower()\n",
    "    df_final['Type'] = df_final.apply(lambda x: 'tutorial' if x['Type'] == 'etc' else x['Type'], axis=1)\n",
    "    return df_final, offer\n",
    "\n",
    "def create_cost_matrix(df_final, offer):\n",
    "    num_offers = len(offer)\n",
    "    num_rooms = len(df_final)\n",
    "    max_size = max(num_offers, num_rooms)\n",
    "    cost_matrix = np.full((max_size, max_size), 1e6)\n",
    "\n",
    "    df_final['Capacity'] = df_final['Capacity'].astype(int)\n",
    "    offer['Capacity'] = offer['Capacity'].astype(int)\n",
    "\n",
    "    # 🔹 교수님이 특정 시간에 중복되지 않도록 하기 위한 매핑\n",
    "    professor_time_map = {}\n",
    "\n",
    "    for i, offer_row in offer.iterrows():\n",
    "        for j, room_row in df_final.iterrows():\n",
    "            assigned_time = (room_row['Assigned Day'], room_row['Assigned Time Slot'])\n",
    "            professor = offer_row['Lecturer']\n",
    "\n",
    "            if (offer_row['Category'] == room_row['Type'] or\n",
    "                (offer_row['Category'] in ['lecture', 'tutorial'] and room_row['Type'] in ['general', 'lecture']) or\n",
    "                (offer_row['Category'] == 'lecture' and room_row['Type'] == 'tutorial' and room_row['Lecture'] == 'Y')):\n",
    "\n",
    "                if room_row['Capacity'] >= offer_row['Capacity']:\n",
    "                    # 🔹 같은 시간대에 이미 배정된 교수님이 있는 경우 패널티를 줌\n",
    "                    if assigned_time in professor_time_map and professor in professor_time_map[assigned_time]:\n",
    "                        cost_matrix[i, j] = 1e6  # 불가능한 배정 (큰 값)\n",
    "                    else:\n",
    "                        cost_matrix[i, j] = room_row['Capacity'] - offer_row['Capacity']\n",
    "\n",
    "    return cost_matrix\n",
    "\n",
    "\n",
    "def assign_classes(df_final, offer):\n",
    "    df_final_expanded = expand_room_slots(df_final)\n",
    "    cost_matrix = create_cost_matrix(df_final_expanded, offer)\n",
    "\n",
    "    num_offers, num_rooms = cost_matrix.shape\n",
    "    max_size = max(num_offers, num_rooms)\n",
    "\n",
    "    if num_offers < max_size:\n",
    "        cost_matrix = np.vstack([cost_matrix, np.full((max_size - num_offers, max_size), 1e6)])\n",
    "    if num_rooms < max_size:\n",
    "        cost_matrix = np.hstack([cost_matrix, np.full((max_size, max_size - num_rooms), 1e6)])\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    assignments = []\n",
    "    professor_time_map = {}  # 🔹 교수님 시간 중복 체크\n",
    "\n",
    "    for r, c in zip(row_ind, col_ind):\n",
    "        if r < len(offer) and c < len(df_final_expanded) and cost_matrix[r, c] != 1e6:\n",
    "            assigned_day = df_final_expanded.iloc[c]['Assigned Day']\n",
    "            assigned_time = df_final_expanded.iloc[c]['Assigned Time Slot']\n",
    "            professor = offer.iloc[r]['Lecturer']\n",
    "\n",
    "            # 🔹 같은 시간에 같은 교수님이 이미 배정된 경우 무조건 제외\n",
    "            if (assigned_day, assigned_time) in professor_time_map and professor in professor_time_map[(assigned_day, assigned_time)]:\n",
    "                continue  # 🚨 이 배정은 무효! 스킵!\n",
    "\n",
    "            # 🔹 교수님 배정 확정 (시간대 저장)\n",
    "            if (assigned_day, assigned_time) not in professor_time_map:\n",
    "                professor_time_map[(assigned_day, assigned_time)] = set()\n",
    "            professor_time_map[(assigned_day, assigned_time)].add(professor)\n",
    "\n",
    "            assignments.append({\n",
    "                'Group': offer.iloc[r]['Course Code'],\n",
    "                'Category': offer.iloc[r]['Category'],\n",
    "                'Lecturer': professor,\n",
    "                'Assigned Room': df_final_expanded.iloc[c]['Resource Code'],\n",
    "                'Room Type': df_final_expanded.iloc[c]['Type'],\n",
    "                'Group Capacity': offer.iloc[r]['Capacity'],\n",
    "                'Room Capacity': df_final_expanded.iloc[c]['Capacity'],\n",
    "                'Assigned Day': assigned_day,\n",
    "                'Assigned Time Slot': assigned_time,\n",
    "                'Lecture': df_final_expanded.iloc[c]['Lecture'],\n",
    "                'Tutorial': df_final_expanded.iloc[c]['Tutorial'],\n",
    "                'Lab': df_final_expanded.iloc[c]['Lab'],\n",
    "                'Duration (min)': offer.iloc[r]['Min Per Session']\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(assignments)\n",
    "\n",
    "\n",
    "def generate_assigned_schedule(df_final, offer):\n",
    "    \"\"\"\n",
    "    Generates the assigned schedule by processing offers and matching them with available rooms.\n",
    "\n",
    "    Parameters:\n",
    "        df_final (pd.DataFrame): The processed resource room DataFrame.\n",
    "        offer (pd.DataFrame): The course offer DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the final class assignments.\n",
    "    \"\"\"\n",
    "    # Determine the maximum room capacity from the resource room DataFrame\n",
    "    max_room_capacity = df_final['Capacity'].astype(int).max()\n",
    "    \n",
    "    # Process the offers by expanding them based on room capacity\n",
    "    offer = preprocess_offers(offer, max_room_capacity)\n",
    "    \n",
    "    # Align the room types and offer categories for matching\n",
    "    df_final, offer = match_classroom_type(df_final, offer)\n",
    "    \n",
    "    # Assign classes based on the constructed cost matrix and constraints\n",
    "    assigned_schedule = assign_classes(df_final, offer)\n",
    "    \n",
    "    return assigned_schedule\n",
    "\n",
    "# Example usage:\n",
    "# assigned_schedule = generate_assigned_schedule(df_final, offer)\n",
    "# print(assigned_schedule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
